\documentclass{article}

% ----------- core mathematics -----------
\usepackage{amsmath}   % align, split, cases, etc.
\usepackage{amssymb}   % \mathbb, \mathcal, \leqslant, \geqslant ...
\usepackage{amsfonts}  % blackboard bold, fraktur if desired
\usepackage{graphicx}  % for future figures, even if none are included yet
\usepackage{listings}  % for code examples
\usepackage{hyperref}  % clickable cross-refs; load last
\usepackage{mdframed}  % for boxed content

% ----------- tables & arrays ------------
\usepackage{array}     % extended column specifiers in tabular
\usepackage{booktabs}  % nicer horizontal rules (optional; you may keep \hline)
\usepackage{multirow}  % multi-row cells if you extend the tables later

% ----------- layout & floats ------------
\usepackage{geometry}  % easy margin control (defaults are fine; optional)
\usepackage{caption}   % better caption spacing for tables/figures

\title{Introduction }
\order{1}
\author{Tutorial Team}
\date{May 21, 2025}

\begin{document}


\section{Introduction}

The \textbf{Hyperon Pattern Miner} is a MeTTa-based system for automatically discovering  frequent and/or \textbf{interesting}  sub-metagraph patterns in Hyperon's AtomSpace metagraph.   And the definition of what is an \textbf{interesting} pattern is fairly flexibly configurable!

The Pattern Miner inverts the logic of pattern-matching.   Instead of asking


"Given a large collection of ground Atoms, and a small template query (a pattern) what portions of the collection match the pattern?"


It asks:

"Given a large collection of ground Atoms, what small template queries (patterns) will produce many matches and/or which ones give the most surprising or otherwise interesting answers?"


This is in general an intractably hard problem and the current approach is to address it heuristically, using greedy heuristics that are crafted via experience to capture a lot of the relevant patterns that seem to arise in real-world contexts.   There is plenty of room to improve or replace these heuristics in future, including potentially to replace them by more fundamentally theoretically-grounded methods.   On the other hand, the heuristics in place now come from decades of practice in frequent pattern mining from relational databases, graphs and other structures, and it seems plausible they can take us a long way, maybe even to HLAGI and beyond (considered as one set of tools within a broader toolkit of methods enabling Atomspaces to evolve and grow toward greater and greater intelligence).



Under the hood, the current Hyperon Pattern Miner implements a multi-stage pipeline as roughly shown  below (this is somewhat in depth and will be reviewed further later on in the tutorial, but we give the whole process here as a prelude so you'll get an idea of what sort of thing you're jumping into !!)

\subsection{Pattern Mining Process}


\begin{enumerate}
  \item \textbf{Extract 1-Clause Templates (Abstract Patterns)}
     \begin{itemize}
        \item Scan every link atom in your AtomSpace (for example, \\
          \verb|(eval (pred "drink") (list (concept "Alice") (concept "Coke")))|).
          \item  For each such link, pick one position (predicate or one of the list elements)
             and replace it with a fresh variable node, \verb|(var "$X")|.  This gives
             a \emph{generic} 1-clause pattern like
               \verb|(eval (pred "drink") (list (var "$X") (concept "Coke")))|.  
         \item Internally this is done by the \texttt{get-links} routine.
      \end{itemize}
  \item \textbf{Generate Grounded Candidates (Specialize)}
    \begin{itemize}
    \item For each abstract 1-clause template, find all actual subgraphs in the AtomSpace
    that match its fixed parts.  
    \item For each match, record the concrete values that
    fill the variable slots.  This produces a collection of \emph{specialized}
    candidate patterns, each paired with its match count.  
    \item The \texttt{specialize}
    and \texttt{support} functions implement this step.
      \end{itemize}
  \item \textbf{Prune by Minimum Support}
    \begin{itemize}
    \item For each candidate pattern, compute its \emph{support} (how many groundings it has)
    via \verb|(match-count pattern)|.  
    \item Discard any pattern whose support is below
    your user-specified threshold \verb|minsup|.  This ensures you only keep
    frequently occurring subgraphs.
      \end{itemize}
  \item \textbf{Build Multi-Clause Patterns (Greedy Conjunction)}
    \begin{itemize}
    \item Take the surviving 1-clause patterns and form 2-clause patterns by pairing
    any two that share at least one variable.  
    \item Conjoin them as
    \verb|(and <pattern1> <pattern2>)|. 
    \item  Again compute support and prune by
    \verb|minsup|. 
    \item  Repeat this ''specialize + prune'' loop to grow 3-clause,
    4-clause, ? up to your desired maximum depth.  
    \item The \texttt{combine-with}
    and recursive \texttt{get-candidate} calls manage this expansion.
      \end{itemize}
  \item \textbf{Rank by Desired "Interestness" measure, e.g. one is called I-Surprisingness}
    \begin{itemize}
    \item For each final pattern, if one is e.g. using the "I-Surprisingness" measure to gauge interestingness, then compute:
    \[
      P_{\mathrm{obs}} = \frac{\text{support}}{\text{universe-size}}
      ,\quad
      P_{\mathrm{exp}} = \prod_{i=1}^{n}P(c_i)
      \quad(\text{assuming independence})\,,
    \]
    where each $P(c_i)$ is the single-clause probability of clause $i$.
    \item Then
    $$
      I = \log\!\Bigl(\frac{P_{\mathrm{obs}}}{P_{\mathrm{exp}}}\Bigr)
      \quad\text{(or a normalized deviation)}.
    $$
    \item Patterns with highest $I$ are the most ''surprising.''  
    \item This scoring is performed by the \texttt{iSurprisingness} function.
  \end{itemize}
\end{enumerate}


\section{Implementation Details}

This whole process is implemented in MeTTa, so if one runs it within a fast MeTTa interpretation or compilation framework, it should scale to huge numbers  of Atoms.  (Different Atoms may have different sizes, but very roughly, in a server with terabytes of RAM one may be able to host Atomspaces with 100B or more Atoms.)   It also exposes a clean API so you can integrate pattern mining directly into larger learning or reasoning pipelines.

\subsection{Current Capabilities and Future Work}

In its current form the Pattern Miner runs against an Atomspace in RAM on a single machine, however the underlying algorithms are well designed for extension to a distributed-processing setting, and we anticipate future Pattern Miner versions working effectlvely on distributed Atomspaces as well.   This further development will be done in conjunction with other existing tools like the Distributed Atomspace (DAS) XX and the Mettacycle decentralized infrastructure (XX).

\section{Details On The Atomspace You Will Be Working On}

All of the live examples on our website operate within a single, shared environment called an "Atomspace," which you can think of as a collective digital whiteboard. As you run each code example, or "cell," you are continuously adding new information to this space, building upon the results from all the cells you have already run. The "Reset" button provides a powerful way to start over from a specific point. When you click it, the system first completely erases the entire Atomspace and then immediately re-initializes it by automatically re-running all the code from the cells that precede the one you are currently on. This action effectively restores the environment to the precise state it was in just before you reached your current example.

\section{Tutorial Objectives}

In this tutorial you will learn to:

\begin{enumerate}
  \item \textbf{Ground yourself} in the core concepts (AtomSpace, patterns, frequency, and surprisingness).
  \item \textbf{Step through} the full mining pipeline--from abstracting link-nodes to scoring surprisingness--using diagrams and MeTTa code.
  \item \textbf{Run hands-on} MeTTa scripts to install, configure, and execute the Hyperon Pattern Miner on your own AtomSpace data.
  \item \textbf{Explore advanced use cases} and performance-tuning strategies so you can apply pattern mining to real-world datasets.
\end{enumerate}

By the end of this tutorial, you'll understand what the Hyperon Pattern Miner is, why it matters, and how it works--and be at least a little bit experienced with some hands-on examples.   You should then be prepared to work on some larger examples on your own if that's the direction your work or interest leads you!

\end{document}